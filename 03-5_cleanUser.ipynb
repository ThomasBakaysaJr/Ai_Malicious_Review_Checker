{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ca8304c-93cb-4cb1-873b-7d804543992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to clean the reviews here.\n",
    "import ast\n",
    "import sys\n",
    "import string\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import autopep8\n",
    "import joblib\n",
    "import gc\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from scipy.sparse import hstack\n",
    "from io import StringIO\n",
    "\n",
    "# do get rid of annoying warnings\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85b822ed-1268-47ae-a771-cde00c8f65ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cleaning\n",
      "Chunk 1 already exits at files/review_chunks/user_clean/user_chunk_01.csv. Skipping\n",
      "Chunk 2 already exits at files/review_chunks/user_clean/user_chunk_02.csv. Skipping\n",
      "Chunk 3 already exits at files/review_chunks/user_clean/user_chunk_03.csv. Skipping\n",
      "Chunk 4 already exits at files/review_chunks/user_clean/user_chunk_04.csv. Skipping\n",
      "Chunk 5 already exits at files/review_chunks/user_clean/user_chunk_05.csv. Skipping\n",
      "Chunk 6 already exits at files/review_chunks/user_clean/user_chunk_06.csv. Skipping\n",
      "Chunk 7 already exits at files/review_chunks/user_clean/user_chunk_07.csv. Skipping\n",
      "Chunk 8 already exits at files/review_chunks/user_clean/user_chunk_08.csv. Skipping\n",
      "Chunk 9 already exits at files/review_chunks/user_clean/user_chunk_09.csv. Skipping\n",
      "Chunk 10 already exits at files/review_chunks/user_clean/user_chunk_010.csv. Skipping\n",
      "Chunk 11 already exits at files/review_chunks/user_clean/user_chunk_011.csv. Skipping\n",
      "Chunk 12 already exits at files/review_chunks/user_clean/user_chunk_012.csv. Skipping\n",
      "Chunk 13 already exits at files/review_chunks/user_clean/user_chunk_013.csv. Skipping\n",
      "Chunk 14 already exits at files/review_chunks/user_clean/user_chunk_014.csv. Skipping\n",
      "Chunk 15 already exits at files/review_chunks/user_clean/user_chunk_015.csv. Skipping\n",
      "Chunk 16 already exits at files/review_chunks/user_clean/user_chunk_016.csv. Skipping\n",
      "Chunk 17 already exits at files/review_chunks/user_clean/user_chunk_017.csv. Skipping\n",
      "Chunk 18 already exits at files/review_chunks/user_clean/user_chunk_018.csv. Skipping\n",
      "Chunk 19 already exits at files/review_chunks/user_clean/user_chunk_019.csv. Skipping\n",
      "Finished labeling reviews after 0.09665211836496988 minutes. Files are seperated into chunks of 100000 lines.\n",
      "Combining chunks\n",
      "Combined. Cleaned review files lives at files/user_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# global, for the print statements\n",
    "verbose = True\n",
    "# set to True so that the notebook tries smaller chunks and only does 5 chunks\n",
    "test = False\n",
    "# How confident does the model need to be to accept the psuedo-label\n",
    "threshold = 0.8\n",
    "# chunk_size (will only use this if test if False)\n",
    "CHUNK_SIZE = 100000\n",
    "# for calculating account age\n",
    "today = pd.Timestamp.today()\n",
    "\n",
    "chunk_save_path = f\"files/review_chunks/user_clean/user_chunk{'_test' if test else ''}_0\"\n",
    "csv_save_path = 'files/user_cleaned.csv'\n",
    "\n",
    "user_file_path = 'reviews/yelpReviews/yelp_academic_dataset_user.json'\n",
    "ussub = ['user_id', 'review_count', 'yelping_since']\n",
    "\n",
    "# going to have read the json file in chunks, the thing is almost 5 gigs\n",
    "chunk_size = 200 if test else CHUNK_SIZE\n",
    "\n",
    "with open(user_file_path, 'r', encoding='utf-8') as file:\n",
    "        chunk = []\n",
    "        chunk_df = pd.DataFrame()\n",
    "        chunk_count = []\n",
    "        count = 1\n",
    "        print(f'Starting cleaning')\n",
    "        t0 = time.time()\n",
    "        # check if this chunk exists already (for restarts)\n",
    "        chunk_path = f'{chunk_save_path}{count}.csv'\n",
    "        \n",
    "        if os.path.exists(chunk_path):\n",
    "            if test:\n",
    "                os.remove(chunk_path)\n",
    "            chunk_count.append(count)\n",
    "        \n",
    "        for index, line in enumerate(file):            \n",
    "            if count not in chunk_count:\n",
    "                # read each line as a dataframe then append to a list\n",
    "                data = json.loads(line)\n",
    "                #data = pd.read_json(StringIO(line), lines = True)\n",
    "                chunk.append(data)\n",
    "            \n",
    "            # check if chunk is full / right now we exit since I'm just trying to clean the thing rn.\n",
    "            if (index + 1) % chunk_size == 0:\n",
    "                if os.path.exists(chunk_path):\n",
    "                    print(f'Chunk {count} already exits at {chunk_path}. Skipping')\n",
    "                else:\n",
    "                    print(f'Starting labeling of chunk {count}.')\n",
    "                    chunk_df = pd.DataFrame(chunk)\n",
    "                    \n",
    "                    # remove the columns we don't care about\n",
    "                    chunk_df = chunk_df[ussub]\n",
    "                    \n",
    "                    chunk_df['yelping_since'] = pd.to_datetime(chunk_df['yelping_since'])\n",
    "                    chunk_df['account_age_years'] = (today - chunk_df['yelping_since']).dt.days / 365.25\n",
    "                    chunk_df = chunk_df.drop(['yelping_since'], axis=1)\n",
    "                    \n",
    "                    # write each chunk to its own file, will combine them later\n",
    "                    chunk_df.to_csv(chunk_path, index=False)\n",
    "                    if verbose:\n",
    "                        print(f'chunk {count} finished at {time.time() - t0} seconds. Saved at {chunk_path}\\n')\n",
    "                        \n",
    "                # garbage collection\n",
    "                del chunk, chunk_df\n",
    "                gc.collect()\n",
    "        \n",
    "                chunk = []\n",
    "                chunk_df = pd.DataFrame()\n",
    "                \n",
    "                if count not in chunk_count:\n",
    "                    chunk_count.append(count)\n",
    "                count += 1\n",
    "                chunk_path = f'{chunk_save_path}{count}.csv'\n",
    "                \n",
    "                if os.path.exists(chunk_path):\n",
    "                    if test:\n",
    "                        os.remove(chunk_path)\n",
    "                    else:\n",
    "                        chunk_count.append(count)\n",
    "                \n",
    "                if test and count > 5:\n",
    "                    break\n",
    "if test:\n",
    "    print('TEST RUN')\n",
    "print(f'Finished labeling reviews after {(time.time() - t0) / 60.0} minutes. Files are seperated into chunks of {chunk_size} lines.')\n",
    "\n",
    "print('Combining chunks')\n",
    "chunk_files = sorted(glob.glob(f'{chunk_save_path}*.csv'))\n",
    "df = pd.concat([pd.read_csv(file) for file in chunk_files], ignore_index = True)\n",
    "df.to_csv(csv_save_path, index=False)\n",
    "print(f'Combined. Cleaned review files lives at {csv_save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b1d189-a45f-4931-823f-031cb71f2439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb02ea-8078-4953-8fb1-839f11eb3614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
