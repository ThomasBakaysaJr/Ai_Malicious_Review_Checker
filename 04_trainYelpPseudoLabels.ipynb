{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef562cd8-dfb1-4ebf-8f46-8c50e7d68288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fb56a8a-0bf7-498a-b2c6-a85d5c7c3f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load pseudo labeled, cleaned business and cleaned user files\n",
      "Files loaded successfully\n"
     ]
    }
   ],
   "source": [
    "yelp_pseudo_df_path = 'files/reviews_pseudo_labeled.csv'\n",
    "yelp_business_df_path = 'files/busCleaned.csv'\n",
    "yelp_user_df_path = 'files/user_cleaned.csv'\n",
    "\n",
    "xtrain_path = 'models/X_train.npy'\n",
    "xtest_path = 'models/X_test.npy'\n",
    "ytrain_path = 'models/y_train.npy'\n",
    "ytest_path = 'models/y_test.npy'\n",
    "cat_ind_path = 'models/cat_ind.npy'\n",
    "\n",
    "final_vectorizer_path = 'files/final_vectorizer.pkl'\n",
    "final_svd_path = 'files/final_svd.pkl'\n",
    "# Try stuff so I don't just keep getting errors if something goes wrong\n",
    "try:\n",
    "    print('Trying to load pseudo labeled, cleaned business and cleaned user files')\n",
    "    review_df = pd.read_csv(yelp_pseudo_df_path)\n",
    "    business_df = pd.read_csv(yelp_business_df_path)\n",
    "    user_df = pd.read_csv(yelp_user_df_path)\n",
    "    print('Files loaded successfully')\n",
    "except FileNotFoundError:\n",
    "    print('One or more files not found. Cannot continue.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4842429d-3e9b-4c2f-8f74-ae6d482f2aa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get everything ready\n",
    "# in case there are any nan values, drop those\n",
    "# also drop postal codes, they got letters in there\n",
    "review_df = review_df.dropna()\n",
    "business_df = business_df.drop(['postal_code'], axis=1)\n",
    "business_df = business_df.fillna(-1) # fill in empty values with -1, should learn that means missing/unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d31cd57-bf3e-4aaf-9347-d07679a248c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "601"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge dataframes\n",
    "final_df = review_df.merge(business_df, on = 'business_id', how = 'left')\n",
    "final_df = final_df.merge(user_df, on = 'user_id', how = 'left')\n",
    "\n",
    "# attributes most likely for a business and user to have\n",
    "# for checking floating reviews\n",
    "check_cols = [\n",
    "    'ByAppointmentOnly', \n",
    "    'RestaurantsPriceRange2',\n",
    "    'BusinessAcceptsCreditCards',\n",
    "    'RestaurantsPriceRange2',\n",
    "    'account_age_years'\n",
    "]\n",
    "final_df = final_df.dropna(subset = check_cols)\n",
    "\n",
    "# clear out the original dataframes from memory\n",
    "del business_df, review_df, user_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b44e094-08cb-4f14-b8e3-c1e050d59429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting vectorization\n",
      "text vectorized after 223.1216824054718 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "print('Starting vectorization')\n",
    "\n",
    "# vectorize review text with tf-idf\n",
    "vizer = TfidfVectorizer(max_features = 100000)\n",
    "x_text = vizer.fit_transform(final_df['text'])\n",
    "\n",
    "# reducing vectorized text dimensions, it gives me over 300,000 features\n",
    "n_components = 300 \n",
    "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "x_text_reduced = svd.fit_transform(x_text)\n",
    "\n",
    "# reduce the text size\n",
    "text_reduced = x_text_reduced.astype(np.float32)\n",
    "print(f'text vectorized after {time.time() - t0} seconds')\n",
    "\n",
    "# save the fitted vectorizers\n",
    "joblib.dump(vizer, final_vectorizer_path)\n",
    "joblib.dump(svd, final_svd_path)\n",
    "# dump them, I need all the memory I can get\n",
    "del vizer, svd, x_text\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20cdae15-5340-4cc9-987e-6b2ca1c650aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['WiFi', 'Alcohol', 'RestaurantsAttire', 'NoiseLevel'], dtype='object')\n",
      "stars                         False\n",
      "ByAppointmentOnly             False\n",
      "BusinessAcceptsCreditCards    False\n",
      "BikeParking                   False\n",
      "RestaurantsPriceRange2        False\n",
      "RestaurantsTakeOut            False\n",
      "RestaurantsDelivery           False\n",
      "Caters                        False\n",
      "WiFi                          False\n",
      "WheelchairAccessible          False\n",
      "HappyHour                     False\n",
      "OutdoorSeating                False\n",
      "HasTV                         False\n",
      "RestaurantsReservations       False\n",
      "DogsAllowed                   False\n",
      "Alcohol                       False\n",
      "GoodForKids                   False\n",
      "RestaurantsAttire             False\n",
      "RestaurantsTableService       False\n",
      "RestaurantsGoodForGroups      False\n",
      "NoiseLevel                    False\n",
      "BusinessAcceptsBitcoin        False\n",
      "BusinessParking_garage        False\n",
      "BusinessParking_street        False\n",
      "BusinessParking_validated     False\n",
      "BusinessParking_lot           False\n",
      "BusinessParking_valet         False\n",
      "Ambience_romantic             False\n",
      "Ambience_intimate             False\n",
      "Ambience_touristy             False\n",
      "Ambience_hipster              False\n",
      "Ambience_divey                False\n",
      "Ambience_classy               False\n",
      "Ambience_trendy               False\n",
      "Ambience_upscale              False\n",
      "Ambience_casual               False\n",
      "GoodForMeal_dessert           False\n",
      "GoodForMeal_latenight         False\n",
      "GoodForMeal_lunch             False\n",
      "GoodForMeal_dinner            False\n",
      "GoodForMeal_brunch            False\n",
      "GoodForMeal_breakfast         False\n",
      "review_count_x                False\n",
      "broadCategory                 False\n",
      "review_count_y                False\n",
      "account_age_years             False\n",
      "dtype: bool\n",
      "\n",
      "Memory usage of X: 110.47 MB\n",
      "\n",
      "final_values data types: float32\n"
     ]
    }
   ],
   "source": [
    "# splits the final data frame into the parts we're going to use\n",
    "drop_cols = ['user_id', 'business_id', 'text']\n",
    "\n",
    "final_df = final_df.drop(drop_cols, axis=1)\n",
    "# convert broad_category to numeric\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "string_cols = final_df.select_dtypes(include='object').columns\n",
    "print(string_cols)\n",
    "final_df[string_cols] = final_df[string_cols].astype(object).replace(-1, 'Unknown')\n",
    "final_df[string_cols] = final_df[string_cols].apply(label_encoder.fit_transform)\n",
    "\n",
    "final_df = final_df.convert_dtypes()\n",
    "\n",
    "y = final_df['pseudo_label']\n",
    "final_df = final_df.drop(['pseudo_label'], axis=1)\n",
    "\n",
    "categorical_features = ['ByAppointmentOnly', 'BusinessAcceptsCreditCards', 'BikeParking',\n",
    "       'RestaurantsPriceRange2', 'RestaurantsTakeOut', 'RestaurantsDelivery',\n",
    "       'Caters', 'WiFi', 'WheelchairAccessible', 'HappyHour', 'OutdoorSeating',\n",
    "       'HasTV', 'RestaurantsReservations', 'DogsAllowed', 'Alcohol',\n",
    "       'GoodForKids', 'RestaurantsAttire', 'RestaurantsTableService',\n",
    "       'RestaurantsGoodForGroups', 'NoiseLevel', 'BusinessAcceptsBitcoin',\n",
    "       'BusinessParking_garage', 'BusinessParking_street',\n",
    "       'BusinessParking_validated', 'BusinessParking_lot',\n",
    "       'BusinessParking_valet', 'Ambience_romantic', 'Ambience_intimate',\n",
    "       'Ambience_touristy', 'Ambience_hipster', 'Ambience_divey',\n",
    "       'Ambience_classy', 'Ambience_trendy', 'Ambience_upscale',\n",
    "       'Ambience_casual', 'GoodForMeal_dessert', 'GoodForMeal_latenight',\n",
    "       'GoodForMeal_lunch', 'GoodForMeal_dinner', 'GoodForMeal_brunch',\n",
    "       'GoodForMeal_breakfast', 'broadCategory']\n",
    "categorical_features_indices = [final_df.columns.get_loc(name) for name in categorical_features]\n",
    "np.save(cat_ind_path, categorical_features_indices)\n",
    "# can't have any null values\n",
    "if verbose:\n",
    "    print(final_df.isnull().any())\n",
    "\n",
    "# force everything to be float32 to save on memory\n",
    "final_values = final_df.values.astype(np.float32)\n",
    "\n",
    "del final_df\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\nMemory usage of X: {final_values.nbytes / (1024**2):.2f} MB\\n\")\n",
    "print(f'final_values data types: {final_values.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "305db76b-ec90-46ee-8dac-366cf8375d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crash point warning!!!\n",
    "X = np.hstack((final_values,x_text_reduced))\n",
    "\n",
    "print(X.dtype)\n",
    "\n",
    "# dump what we can\n",
    "del x_text_reduced, final_values\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "120425e4-6867-40b9-97fb-905f4b875440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "Np arrays saved. Ready for training.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "del X\n",
    "gc.collect()\n",
    "\n",
    "print(X_train.dtype)\n",
    "np.save(xtrain_path, X_train)\n",
    "np.save(xtest_path, X_test)\n",
    "np.save(ytrain_path, y_train)\n",
    "np.save(ytest_path, y_test)\n",
    "\n",
    "print('Np arrays saved. Ready for training.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beacb3e-92b5-47c4-b107-0ef7ca2f3ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
