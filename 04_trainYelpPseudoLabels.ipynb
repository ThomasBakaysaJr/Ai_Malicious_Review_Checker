{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef562cd8-dfb1-4ebf-8f46-8c50e7d68288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fb56a8a-0bf7-498a-b2c6-a85d5c7c3f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load pseudo labeled, cleaned business and cleaned user files\n",
      "Files loaded successfully\n"
     ]
    }
   ],
   "source": [
    "yelp_pseudo_df_path = 'files/reviews_pseudo_labeled.csv'\n",
    "yelp_business_df_path = 'files/busCleaned.csv'\n",
    "yelp_user_df_path = 'files/user_cleaned.csv'\n",
    "\n",
    "xtrain_path = 'models/X_train.npy'\n",
    "xtest_path = 'models/X_test.npy'\n",
    "ytrain_path = 'models/y_train.npy'\n",
    "ytest_path = 'models/y_test.npy'\n",
    "cat_ind_path = 'models/cat_ind.npy'\n",
    "\n",
    "final_vectorizer_path = 'files/final_vectorizer.pkl'\n",
    "final_svd_path = 'files/final_svd.pkl'\n",
    "# Try stuff so I don't just keep getting errors if something goes wrong\n",
    "try:\n",
    "    print('Trying to load pseudo labeled, cleaned business and cleaned user files')\n",
    "    review_df = pd.read_csv(yelp_pseudo_df_path)\n",
    "    business_df = pd.read_csv(yelp_business_df_path)\n",
    "    user_df = pd.read_csv(yelp_user_df_path)\n",
    "    print('Files loaded successfully')\n",
    "except FileNotFoundError:\n",
    "    print('One or more files not found. Cannot continue.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4842429d-3e9b-4c2f-8f74-ae6d482f2aa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get everything ready\n",
    "# in case there are any nan values, drop those\n",
    "# also drop postal codes, they got letters in there\n",
    "review_df = review_df.dropna()\n",
    "business_df = business_df.drop(['postal_code'], axis=1)\n",
    "business_df = business_df.fillna(-1) # fill in empty values with -1, should learn that means missing/unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d31cd57-bf3e-4aaf-9347-d07679a248c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge dataframes\n",
    "final_df = review_df.merge(business_df, on = 'business_id', how = 'left')\n",
    "final_df = final_df.merge(user_df, on = 'user_id', how = 'left')\n",
    "\n",
    "# attributes most likely for a business and user to have\n",
    "# for checking floating reviews\n",
    "check_cols = [\n",
    "    'ByAppointmentOnly', \n",
    "    'RestaurantsPriceRange2',\n",
    "    'BusinessAcceptsCreditCards',\n",
    "    'RestaurantsPriceRange2',\n",
    "    'account_age_years'\n",
    "]\n",
    "final_df = final_df.dropna(subset = check_cols)\n",
    "\n",
    "# clear out the original dataframes from memory\n",
    "del business_df, review_df, user_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b44e094-08cb-4f14-b8e3-c1e050d59429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting vectorization\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m n_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m \n\u001b[1;32m     10\u001b[0m svd \u001b[38;5;241m=\u001b[39m TruncatedSVD(n_components\u001b[38;5;241m=\u001b[39mn_components, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m x_text_reduced \u001b[38;5;241m=\u001b[39m \u001b[43msvd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# reduce the text size\u001b[39;00m\n\u001b[1;32m     14\u001b[0m text_reduced \u001b[38;5;241m=\u001b[39m x_text_reduced\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.10/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:244\u001b[0m, in \u001b[0;36mTruncatedSVD.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;241m>\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    241\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be <=\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m n_features(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m         )\n\u001b[0;32m--> 244\u001b[0m     U, Sigma, VT \u001b[38;5;241m=\u001b[39m \u001b[43mrandomized_svd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_oversamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_oversamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpower_iteration_normalizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpower_iteration_normalizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflip_sign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m     U, VT \u001b[38;5;241m=\u001b[39m svd_flip(U, VT, u_based_decision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents_ \u001b[38;5;241m=\u001b[39m VT\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:189\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.10/site-packages/sklearn/utils/extmath.py:524\u001b[0m, in \u001b[0;36mrandomized_svd\u001b[0;34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state, svd_lapack_driver)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transpose:\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;66;03m# this implementation is a bit faster with smaller shape[1]\u001b[39;00m\n\u001b[1;32m    522\u001b[0m     M \u001b[38;5;241m=\u001b[39m M\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m--> 524\u001b[0m Q \u001b[38;5;241m=\u001b[39m \u001b[43mrandomized_range_finder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_random\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpower_iteration_normalizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpower_iteration_normalizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# project M to the (k + p) dimensional space using the basis vectors\u001b[39;00m\n\u001b[1;32m    533\u001b[0m B \u001b[38;5;241m=\u001b[39m Q\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m M\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.10/site-packages/sklearn/utils/extmath.py:336\u001b[0m, in \u001b[0;36mrandomized_range_finder\u001b[0;34m(A, size, n_iter, power_iteration_normalizer, random_state)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iter):\n\u001b[1;32m    335\u001b[0m     Q, _ \u001b[38;5;241m=\u001b[39m normalizer(A \u001b[38;5;241m@\u001b[39m Q)\n\u001b[0;32m--> 336\u001b[0m     Q, _ \u001b[38;5;241m=\u001b[39m normalizer(\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m)\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# Sample the range of A using by linear projection of Q\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# Extract an orthonormal basis\u001b[39;00m\n\u001b[1;32m    340\u001b[0m Q, _ \u001b[38;5;241m=\u001b[39m qr_normalizer(A \u001b[38;5;241m@\u001b[39m Q)\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.10/site-packages/scipy/sparse/_base.py:732\u001b[0m, in \u001b[0;36m_spbase.__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    731\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 732\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matmul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.10/site-packages/scipy/sparse/_base.py:624\u001b[0m, in \u001b[0;36m_spbase._matmul_dispatch\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(M, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m N:\n\u001b[0;32m--> 624\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matmul_multivector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;66;03m# scalar value\u001b[39;00m\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_scalar(other)\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.10/site-packages/scipy/sparse/_compressed.py:539\u001b[0m, in \u001b[0;36m_cs_matrix._matmul_multivector\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# csr_matvecs or csc_matvecs\u001b[39;00m\n\u001b[1;32m    538\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_matvecs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 539\u001b[0m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_vecs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m   \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape((n_vecs,))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "print('Starting vectorization')\n",
    "\n",
    "# vectorize review text with tf-idf\n",
    "vizer = TfidfVectorizer(max_features = 100000)\n",
    "x_text = vizer.fit_transform(final_df['text'])\n",
    "\n",
    "# reducing vectorized text dimensions, it gives me over 300,000 features\n",
    "n_components = 300 \n",
    "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "x_text_reduced = svd.fit_transform(x_text)\n",
    "\n",
    "# reduce the text size\n",
    "text_reduced = x_text_reduced.astype(np.float32)\n",
    "print(f'text vectorized after {time.time() - t0} seconds')\n",
    "\n",
    "# save the fitted vectorizers\n",
    "joblib.dump(vizer, final_vectorizer_path)\n",
    "joblib.dump(svd, final_svd_path)\n",
    "# dump them, I need all the memory I can get\n",
    "del vizer, svd, x_text\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cdae15-5340-4cc9-987e-6b2ca1c650aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits the final data frame into the parts we're going to use\n",
    "drop_cols = ['user_id', 'business_id', 'text']\n",
    "\n",
    "final_df = final_df.drop(drop_cols, axis=1)\n",
    "# convert broad_category to numeric\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "final_df = final_df.convert_dtypes()\n",
    "\n",
    "y = final_df['pseudo_label']\n",
    "final_df = final_df.drop(['pseudo_label'], axis=1)\n",
    "\n",
    "categorical_features = ['ByAppointmentOnly', 'BusinessAcceptsCreditCards', 'BikeParking',\n",
    "       'RestaurantsPriceRange2', 'RestaurantsTakeOut', 'RestaurantsDelivery',\n",
    "       'Caters', 'WiFi', 'WheelchairAccessible', 'HappyHour', 'OutdoorSeating',\n",
    "       'HasTV', 'RestaurantsReservations', 'DogsAllowed', 'Alcohol',\n",
    "       'GoodForKids', 'RestaurantsAttire', 'RestaurantsTableService',\n",
    "       'RestaurantsGoodForGroups', 'NoiseLevel', 'BusinessAcceptsBitcoin',\n",
    "       'BusinessParking_garage', 'BusinessParking_street',\n",
    "       'BusinessParking_validated', 'BusinessParking_lot',\n",
    "       'BusinessParking_valet', 'Ambience_romantic', 'Ambience_intimate',\n",
    "       'Ambience_touristy', 'Ambience_hipster', 'Ambience_divey',\n",
    "       'Ambience_classy', 'Ambience_trendy', 'Ambience_upscale',\n",
    "       'Ambience_casual', 'GoodForMeal_dessert', 'GoodForMeal_latenight',\n",
    "       'GoodForMeal_lunch', 'GoodForMeal_dinner', 'GoodForMeal_brunch',\n",
    "       'GoodForMeal_breakfast', 'broadCategory']\n",
    "\n",
    "# replace -1 with 'unknown' so that encoder works\n",
    "string_cols = final_df.select_dtypes(include='object').columns\n",
    "final_df[string_cols] = final_df[string_cols].astype(object).replace(-1, 'Unknown')\n",
    "# encode the categorical featurs\n",
    "final_df[categorical_features] = final_df[categorical_features].apply(label_encoder.fit_transform)\n",
    "categorical_features_indices = [final_df.columns.get_loc(name) for name in categorical_features]\n",
    "\n",
    "if verbose:\n",
    "    display(final_df.head(10))\n",
    "\n",
    "# save categorical_features for training the model\n",
    "np.save(cat_ind_path, categorical_features_indices)\n",
    "# can't have any null values\n",
    "if verbose:\n",
    "    print(final_df.isnull().any())\n",
    "\n",
    "# force everything to be float32 to save on memory\n",
    "final_values = final_df.values.astype(np.float32)\n",
    "\n",
    "del final_df\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\nMemory usage of X: {final_values.nbytes / (1024**2):.2f} MB\\n\")\n",
    "print(f'final_values data types: {final_values.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305db76b-ec90-46ee-8dac-366cf8375d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crash point warning!!!\n",
    "X = np.hstack((final_values,x_text_reduced))\n",
    "\n",
    "print(X.dtype)\n",
    "\n",
    "# dump what we can\n",
    "del x_text_reduced, final_values\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120425e4-6867-40b9-97fb-905f4b875440",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "del X\n",
    "gc.collect()\n",
    "\n",
    "print(X_train.dtype)\n",
    "np.save(xtrain_path, X_train)\n",
    "np.save(xtest_path, X_test)\n",
    "np.save(ytrain_path, y_train)\n",
    "np.save(ytest_path, y_test)\n",
    "\n",
    "print('Np arrays saved. Ready for training.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beacb3e-92b5-47c4-b107-0ef7ca2f3ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
