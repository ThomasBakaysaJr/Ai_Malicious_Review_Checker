{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef562cd8-dfb1-4ebf-8f46-8c50e7d68288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import time\n",
    "import gc\n",
    "import glob\n",
    "from io import StringIO\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb56a8a-0bf7-498a-b2c6-a85d5c7c3f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_files = sorted(glob.glob('files/review_chunks/zip_cleaned_data_0*.csv'))\n",
    "zip_df = pd.concat([pd.read_csv(file) for file in chunk_files], ignore_index = True)\n",
    "zip_df.to_csv('files/zip_cleaned_data_FULL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5529b01e-ffe4-4cad-b7dc-ffd4e419b11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2100000, 3)\n",
      "label\n",
      "1    2100000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(zip_df.shape)\n",
    "print(zip_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4842429d-3e9b-4c2f-8f74-ae6d482f2aa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# structure of the dataframe should be [text, rating, label]\n",
    "# vectorize with tf-idf\n",
    "vizer = TfidfVectorizer()\n",
    "\n",
    "x_text = vizer.fit_transform(zip_df['text'])\n",
    "\n",
    "if verbose:\n",
    "    print(x_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d31cd57-bf3e-4aaf-9347-d07679a248c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the sparse matrix with the dense ratings column\n",
    "\n",
    "# turn into 2d array\n",
    "rate_feature = zip_df['rating'].values.reshape(-1, 1)\n",
    "\n",
    "# combine vectorized text and ratings\n",
    "# data\n",
    "X = hstack([x_text, rate_feature])\n",
    "\n",
    "# target labels\n",
    "y = zip_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120425e4-6867-40b9-97fb-905f4b875440",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "c_params = [1.0, 0.7, 0.5, 0.3]\n",
    "clf_names = []\n",
    "\n",
    "# train the thing || trying differnt C score on SVM and Logistic Regression\n",
    "models = {}\n",
    "\n",
    "for c in c_params:\n",
    "    # create a svm model with this c value\n",
    "    name = 'clf_svm' + str(c)\n",
    "    clf_names.append(name)\n",
    "    models[name] = LinearSVC(C=c)\n",
    "\n",
    "    t0 = time.time()\n",
    "    if verbose:\n",
    "        print(f'Training {name}')\n",
    "    # actual training\n",
    "    models[name].fit(X_train, y_train)\n",
    "    if verbose:\n",
    "        print(f'finished after {time.time() - t0} seconds')\n",
    "\n",
    "    # create a logistic regression model with this c value\n",
    "    name = 'clf_log' + str(c)\n",
    "    clf_names.append(name)\n",
    "    models[name] = LogisticRegression(C=c, max_iter=1000)\n",
    "\n",
    "    t0 = time.time()\n",
    "    if verbose:\n",
    "        print(f'Training {name}')\n",
    "    # actual training\n",
    "    models[name].fit(X_train, y_train)\n",
    "    if verbose:\n",
    "        print(f'finished after {time.time() - t0} seconds')\n",
    "\n",
    "\n",
    "if verbose:\n",
    "    print('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf43cd3-5cdd-4142-96dc-9c115aef02df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name in clf_names:\n",
    "    y_pred = models[name].predict(X_test)\n",
    "    print(f'Classification report for {name}')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc89f5c-8bf9-4971-9cd3-34c68d5a07fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nothing really beat the SVM with C=1.0\n",
    "# going to save that one and the vectorized (tf-idf)\n",
    "# important because the model trained on this\n",
    "# any new words might give me garbage.\n",
    "# joblib.dump(models['clf_svm1.0'], 'models/support_svm.pkl')\n",
    "# joblib.dump(models['clf_log1.0'], 'models/support_log.pkl')\n",
    "# joblib.dump(models['clf_for'], 'models/support_for.pkl')\n",
    "# joblib.dump(vizer, 'models/support_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42fa3e2-17bb-4d19-a208-7f39d6778d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bac6491-ace6-4a73-8a44-02b0431bac9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
