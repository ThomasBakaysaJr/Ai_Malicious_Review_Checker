{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ca8304c-93cb-4cb1-873b-7d804543992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get overwrite files, just remove the .mark files\n",
    "\n",
    "# This is specifically for cleaning reviews for predicting ratings\n",
    "# going to clean the reviews here.\n",
    "import ast\n",
    "import sys\n",
    "import string\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import autopep8\n",
    "import joblib\n",
    "import gc\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from scipy.sparse import hstack\n",
    "from io import StringIO\n",
    "\n",
    "# do get rid of annoying warnings\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8862ce46-fcb1-4da2-9c7c-21a38f524c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global, for the print statements\n",
    "verbose = True\n",
    "# set to True so that the notebook tries smaller chunks and only does 5 chunks\n",
    "test = False\n",
    "# chunk_size (will only use this if test if False)\n",
    "CHUNK_SIZE = 5000\n",
    "\n",
    "chunk_save_path = f\"files/review_chunks/no_label/rating_group/review_chunk\"\n",
    "# mark's only purpose is to inform the loop that this file exists or not\n",
    "mark_path = f\"files/review_chunks/no_label/rating_group/mark_{'_test' if test else ''}_0\"\n",
    "# starting at 0 since ML models like 0 indexed variables\n",
    "star_values = [0,1,2,3,4]\n",
    "\n",
    "rwpath = 'reviews/yelpReviews/yelp_academic_dataset_review.json'\n",
    "# cols we want from the reviews\n",
    "rwsub = ['user_id', 'business_id', 'text', 'date', 'stars']\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e40587d-71b2-4883-9ffd-8576b4bf13aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts to lowercase and strip punctuation\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85b822ed-1268-47ae-a771-cde00c8f65ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting labeling\n",
      "Chunk 1 for star value 0 saved.\n",
      "Chunk 1 for star value 1 saved.\n",
      "Chunk 1 for star value 2 saved.\n",
      "Chunk 1 for star value 3 saved.\n",
      "Chunk 1 for star value 4 saved.\n",
      "chunk 1 finished at 0.3356940746307373 seconds.\n",
      "\n",
      "Chunk 2 for star value 0 saved.\n",
      "Chunk 2 for star value 1 saved.\n",
      "Chunk 2 for star value 2 saved.\n",
      "Chunk 2 for star value 3 saved.\n",
      "Chunk 2 for star value 4 saved.\n",
      "chunk 2 finished at 0.6643383502960205 seconds.\n",
      "\n",
      "Chunk 3 for star value 0 saved.\n",
      "Chunk 3 for star value 1 saved.\n",
      "Chunk 3 for star value 2 saved.\n",
      "Chunk 3 for star value 3 saved.\n",
      "Chunk 3 for star value 4 saved.\n",
      "chunk 3 finished at 0.9719483852386475 seconds.\n",
      "\n",
      "Chunk 4 for star value 0 saved.\n",
      "Chunk 4 for star value 1 saved.\n",
      "Chunk 4 for star value 2 saved.\n",
      "Chunk 4 for star value 3 saved.\n",
      "Chunk 4 for star value 4 saved.\n",
      "chunk 4 finished at 1.252509355545044 seconds.\n",
      "\n",
      "Chunk 5 for star value 0 saved.\n",
      "Chunk 5 for star value 1 saved.\n",
      "Chunk 5 for star value 2 saved.\n",
      "Chunk 5 for star value 3 saved.\n",
      "Chunk 5 for star value 4 saved.\n",
      "chunk 5 finished at 1.5537691116333008 seconds.\n",
      "\n",
      "TEST RUN\n",
      "Finished chunking reviews after 0.025901071230570474 minutes. Files are seperated into chunks of 200 lines.\n"
     ]
    }
   ],
   "source": [
    "# going to have read the json file in chunks, the thing is almost 5 gigs\n",
    "chunk_size = 200 if test else CHUNK_SIZE\n",
    "\n",
    "with open(rwpath, 'r', encoding='utf-8') as file:\n",
    "    # create a chunk for each star, we will be saving these grouped together\n",
    "    chunk_dic = {}\n",
    "    for value in star_values:\n",
    "        chunk_dic[value] = []\n",
    "    chunk_count = []\n",
    "    count = 1\n",
    "\n",
    "    print(f'Starting labeling')\n",
    "    t0 = time.time()\n",
    "\n",
    "    # check if this chunk exists already (for restarts)\n",
    "    check_path = f'{mark_path}{count}.mark' \n",
    "    if os.path.exists(check_path):\n",
    "        chunk_count.append(count)\n",
    "    \n",
    "    for index, line in enumerate(file):\n",
    "        # only load and save the line if this chunk hasn't been done yet\n",
    "        if count not in chunk_count:\n",
    "            # read each line as a dataframe then append to a list\n",
    "            data = json.loads(line)\n",
    "            #data = pd.read_json(StringIO(line), lines = True)\n",
    "            # determine which dataframe to put this json object in\n",
    "            # star = star - 1 to make it zero indexed\n",
    "            star = data['stars'] = int(data['stars'])\n",
    "            chunk_dic[star - 1].append(data)\n",
    "        \n",
    "        # check if chunk is full \n",
    "        if (index + 1) % chunk_size == 0:\n",
    "            if count in chunk_count:\n",
    "                print(f'Chunks {count} already exits. Skipping')\n",
    "            else:\n",
    "                # convert json object lists into dataframes. remove\n",
    "                # columns we don't care about. The text also gets cleaned\n",
    "                for star in star_values:\n",
    "                    data = chunk_dic[star]\n",
    "                    data_df = pd.DataFrame(data) # convert to df\n",
    "                    data_df['text'] = data_df['text'].apply(clean_text) # clean text\n",
    "                    data_df['stars'] = data_df['stars'] - 1 # change so stars are z\n",
    "                    data_df = data_df[rwsub] # only keep relevant cols\n",
    "                    data_df.to_csv(f\"{chunk_save_path}_star{star}_0{count}.csv\", index = False)\n",
    "                    \n",
    "                    del data_df, data, chunk_dic[star]\n",
    "                    gc.collect()\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f'Chunk {count} for star value {star} saved.')\n",
    "\n",
    "                if verbose:\n",
    "                    print(f'chunk {count} finished at {time.time() - t0} seconds.\\n')\n",
    "\n",
    "            # mark this as finished by saving the mark\n",
    "            mark_save_path = f\"{mark_path}{count}.mark\"\n",
    "            with open(mark_save_path, 'w') as f:\n",
    "                pass\n",
    "            \n",
    "            # clear dictionary for next loop\n",
    "            chunk_dic.clear()\n",
    "            for value in star_values:\n",
    "                chunk_dic[value] = []\n",
    "            \n",
    "            if count not in chunk_count:\n",
    "                chunk_count.append(count)\n",
    "            count += 1\n",
    "\n",
    "            mark_save_path = f\"{mark_path}{count}.mark\"\n",
    "            if os.path.exists(mark_save_path):\n",
    "                chunk_count.append(count)\n",
    "            \n",
    "            if test and count > 5:\n",
    "                break\n",
    "if test:\n",
    "    print('TEST RUN')\n",
    "print(f'Finished chunking reviews after {(time.time() - t0) / 60.0} minutes. Files are seperated into chunks of {chunk_size} lines.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b1d189-a45f-4931-823f-031cb71f2439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb02ea-8078-4953-8fb1-839f11eb3614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
